{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 581.0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 40569.0,
     "status": "ok",
     "timestamp": 1.552512786989E12,
     "user": {
      "displayName": "Hossein Akhlaghpour",
      "photoUrl": "https://lh4.googleusercontent.com/-mlpqFUaVkFg/AAAAAAAAAAI/AAAAAAAACmQ/pK_v5G4eX5g/s64/photo.jpg",
      "userId": "12694174172773933543"
     },
     "user_tz": 420.0
    },
    "id": "rxHUoabn9tFd",
    "outputId": "f84f1db0-5a3b-4e40-d5c7-5b9e8af02926"
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow==2.0.0-alpha # for colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "13KZ4Jnw_hZx"
   },
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "max_features = 10000\n",
    "maxlen = 400\n",
    "\n",
    "print('Loading data...')\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=max_features)\n",
    "print(len(train_data), 'train sequences')\n",
    "print(len(test_data), 'test sequences')\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "train_data = sequence.pad_sequences(train_data, maxlen=maxlen)\n",
    "test_data = sequence.pad_sequences(test_data, maxlen=maxlen)\n",
    "print('train_data shape:', train_data.shape)\n",
    "print('test_data shape:', test_data.shape)\n",
    "\n",
    "train_data = sequence.pad_sequences(train_data, maxlen=maxlen)\n",
    "test_data = sequence.pad_sequences(test_data, maxlen=maxlen)\n",
    "\n",
    "print(train_data[0])\n",
    "print(test_data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1LcqqUblBM_s"
   },
   "outputs": [],
   "source": [
    "\n",
    "# A dictionary mapping words to an integer index\n",
    "word_index = imdb.get_word_index()\n",
    "\n",
    "# The first indices are reserved\n",
    "word_index = {k:(v+3) for k,v in word_index.items()} \n",
    "word_index[\"<PAD>\"] = 0\n",
    "word_index[\"<START>\"] = 1\n",
    "word_index[\"<UNK>\"] = 2  # unknown\n",
    "word_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "def decode_review(text):\n",
    "    return ' '.join([reverse_word_index.get(i, '?') for i in text])\n",
    "\n",
    "decode_review(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1LcqqUblBM_s"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "print(\"Training entries: {}, labels: {}\".format(len(train_data), len(train_labels)))\n",
    "\n",
    "train_data = pad_sequences(train_data, value=word_index[\"<PAD>\"], padding='post', maxlen=256)\n",
    "test_data = pad_sequences(test_data, \n",
    "                                                       value=word_index[\"<PAD>\"], \n",
    "                                                       padding='post',\n",
    "                                                       maxlen=256)\n",
    "\n",
    "\n",
    "print(len(train_data[0]), len(train_data[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1LcqqUblBM_s"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, \\\n",
    "    Conv1D, GlobalMaxPooling1D, GlobalAveragePooling1D, Embedding\n",
    "from tensorflow.nn import relu, sigmoid\n",
    "from tensorflow.keras.backend import binary_crossentropy\n",
    "\n",
    "\n",
    "# set parameters:\n",
    "embedding_dims = 50\n",
    "filters = 250\n",
    "kernel_size = 3\n",
    "hidden_dims = 250\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# input shape is the vocabulary count used for the movie reviews (10,000 words)\n",
    "vocab_size = 10000\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 16))\n",
    "#model.add(Embedding(max_features, embedding_dims, input_length=maxlen))\n",
    "#model.add(Dropout(0.2))\n",
    "#model.add(Conv1D(filters, kernel_size, padding='valid', activation=relu, strides=1))\n",
    "#model.add(GlobalMaxPooling1D())\n",
    "model.add(GlobalAveragePooling1D())\n",
    "#model.add(Dense(250, activation=relu))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(16, activation=relu))\n",
    "model.add(Dense(1, activation=sigmoid))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=binary_crossentropy,\n",
    "              metrics=['acc']\n",
    "              )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_validation_data = train_data[:10000]\n",
    "partial_train_data = train_data[10000:]\n",
    "\n",
    "partial_validation_labels = train_labels[:10000]\n",
    "partial_train_labels = train_labels[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221.0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 29302.0,
     "status": "ok",
     "timestamp": 1.552514507534E12,
     "user": {
      "displayName": "Hossein Akhlaghpour",
      "photoUrl": "https://lh4.googleusercontent.com/-mlpqFUaVkFg/AAAAAAAAAAI/AAAAAAAACmQ/pK_v5G4eX5g/s64/photo.jpg",
      "userId": "12694174172773933543"
     },
     "user_tz": 420.0
    },
    "id": "1H0185IXEYiz",
    "outputId": "58e988a7-0138-4bd9-88a5-ec060a19011c"
   },
   "outputs": [],
   "source": [
    "batch_size = 512 # 32\n",
    "epochs=40 # 2\n",
    "\n",
    "history = model.fit(partial_train_data,\n",
    "                    partial_train_labels,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    validation_data=(partial_validation_data, partial_validation_labels),\n",
    "                    verbose=1)\n",
    "# history = model.fit(test_data, test_labels, batch_size=batch_size, epochs=epochs, verbose=1)\n",
    "model.evaluate(test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WwdWlz4wpTPP"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict['acc']\n",
    "val_acc = history_dict['val_acc']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()   # clear figure\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
