{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "restore checkpoint in iris sample.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hossein20s/tutorial/blob/master/restore_checkpoint_in_iris_sample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "loczEdjMc_vL",
        "colab_type": "code",
        "outputId": "3b4fe5ba-9b24-4864-d9ed-d59522ca05ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.13.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zK05J3RKseZA",
        "colab_type": "code",
        "outputId": "5f2014d4-78f7-4642-b8f8-b0d532bc453b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "sys.path.append('/content/gdrive/My Drive/python-lib')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "z9zEy7Upl1q6",
        "colab_type": "code",
        "outputId": "3206487e-81c6-4ad7-b11f-a79013b63bfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "import iris_data\n",
        "\n",
        "#Fetch the data\n",
        "(train_x, train_y), (test_x, test_y) = iris_data.load_data()\n",
        "\n",
        "# Feature columns describe how to use the input.\n",
        "my_feature_columns = []\n",
        "for key in train_x.keys():\n",
        "  my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
        "\n",
        "print(my_feature_columns)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[NumericColumn(key='SepalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='SepalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ih93dGhEhmfb",
        "colab_type": "code",
        "outputId": "260d8a37-5da6-4c90-d82e-61cd883c5a9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:    \n",
        "    saver = tf.train.import_meta_graph('gdrive/My Drive/models/iris/model.ckpt-200.meta')\n",
        "    saver.restore(sess,tf.train.latest_checkpoint('gdrive/My Drive/models/iris/'))\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from models/iris/model.ckpt-200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1kc0Al3Vlr3W",
        "colab_type": "code",
        "outputId": "6d24d421-0778-47f4-b6e0-54c280932a32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "cell_type": "code",
      "source": [
        "classifier = tf.estimator.DNNClassifier(\n",
        "    feature_columns=my_feature_columns,\n",
        "    hidden_units=[10, 10],\n",
        "    n_classes=3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpjb6kfhab\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpjb6kfhab', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fcbf6fec5c0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5tvuwnNhmGr8",
        "colab_type": "code",
        "outputId": "530b259f-47f0-4d8a-b85d-24f88f5d7195",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "cell_type": "code",
      "source": [
        " # Generate predictions from the model\n",
        "expected = ['Setosa', 'Versicolor', 'Virginica']\n",
        "predict_x = {\n",
        "        'SepalLength': [5.1, 5.9, 6.9],\n",
        "        'SepalWidth': [3.3, 3.0, 3.1],\n",
        "        'PetalLength': [1.7, 4.2, 5.4],\n",
        "        'PetalWidth': [0.5, 1.5, 2.1],\n",
        "}\n",
        "\n",
        "predictions = classifier.predict(\n",
        "  input_fn=lambda:iris_data.eval_input_fn(predict_x,\n",
        "                                         labels=None,\n",
        "                                         batch_size=100),\n",
        "                                         checkpoint_path='gdrive/My Drive/models/iris/model.ckpt-200')\n",
        "\n",
        "template = ('\\nPrediction is \"{}\" ({:.1f}%), expected \"{}\"')\n",
        "\n",
        "for pred_dict, expec in zip(predictions, expected):\n",
        "        class_id = pred_dict['class_ids'][0]\n",
        "        probability = pred_dict['probabilities'][class_id]\n",
        "\n",
        "        print(template.format(iris_data.SPECIES[class_id],\n",
        "                              100 * probability, expec))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gdrive/My Drive/models/iris/model.ckpt-200\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "\n",
            "Prediction is \"Setosa\" (97.8%), expected \"Setosa\"\n",
            "\n",
            "Prediction is \"Versicolor\" (85.4%), expected \"Versicolor\"\n",
            "\n",
            "Prediction is \"Virginica\" (83.2%), expected \"Virginica\"\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}